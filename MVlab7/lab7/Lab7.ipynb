{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 7\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return x*(1.0-x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [ -2.17351859e-05]\n",
      "[0 1] [ 0.99700249]\n",
      "[1 0] [ 0.99634075]\n",
      "[1 1] [ 0.00327818]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "\n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiMoGAQEZERFAwiIjLC/werkYaTx194UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x48fcb6a860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] [ 0.01443903  0.00136238  0.01471669]\n",
      "[0 1] [ 0.98388982  0.99131382  0.98240503]\n",
      "[1 0] [ 0.9839415   0.99134751  0.98246059]\n",
      "[1 1] [ 0.01806467  0.01008509  0.01846938]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = sigmoid\n",
    "        self.activation_prime = sigmoid_prime\n",
    "\n",
    "# Set weights\n",
    "        self.weights = []\n",
    "# layers = [2,2,1]\n",
    "# range of weight values (-1,1)\n",
    "# input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "# output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "# Add column of ones to X\n",
    "# This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "        myList=[]\n",
    "        avList=[]\n",
    "\n",
    "\n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "    \n",
    "            for l in range(len(self.weights)):\n",
    "                dot_value = np.dot(a[l], self.weights[l])\n",
    "                activation = self.activation(dot_value)\n",
    "                a.append(activation)\n",
    "# output layer\n",
    "\n",
    "\n",
    "            error = y[i] - a[-1]\n",
    "            myList.append(np.sum(error**2))# mean squard error MSE\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# we need to begin at the second to last layer\n",
    "# (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1):\n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "# reverse\n",
    "# [level3(output)->level2(hidden)] => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "# backpropagation\n",
    "# 1. Multiply its output delta and input activation\n",
    "# to get the gradient of the weight.\n",
    "# 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "\n",
    "            cnt = 0\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                cnt =cnt + layer.T.dot(delta)\n",
    "                self.weights[i] =self.weights[i]+ learning_rate * cnt# save in smthing momentum\n",
    "            t = np.average(myList)\n",
    "            avList.append(t)\n",
    "            if k % 10000 == 0:\n",
    "                print('epochs:', k)\n",
    "                t = np.average(myList)\n",
    "                avList.append(t)\n",
    "\n",
    "# plt.show()\n",
    "#print(myList)\n",
    "\n",
    "#plt.plot(myList[1])\n",
    "        plt.plot(avList)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('error')\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))\n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "# X = np.array([[-1, -1],\n",
    "# [-1, 1],\n",
    "# [1, -1],\n",
    "# [1, 1]])\n",
    "# y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
