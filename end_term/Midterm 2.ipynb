{
 "cells": [
  {
   "attachments": {
    "front_page.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm 2 - MNIST Classification\n",
    "![front_page.png](attachment:front_page.png)\n",
    "### Preparing environment and dataset:\n",
    "* pip install python-mnist\n",
    "* create folder midterm/data\n",
    "* download from https://drive.google.com/open?id=1AQwyy3xP7rjDWMPkWBW4kKOfpkIyAWt8 - 4 files\n",
    "* extract all files to ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The error of your classifier on test dataset must be better then 12.0% LeCun et al. 1998\n",
    "#### Enter your error at https://goo.gl/forms/r52T6newOqn1Wcw03\n",
    "#### Commit your code to github/bitbucket into folder midterm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of train images 60000\n",
      "The amount of test images 10000\n",
      "The label of random image 4 The random image is \n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "..................@.........\n",
      ".................@@.........\n",
      ".................@@.........\n",
      "..........@......@@.........\n",
      "..........@......@..........\n",
      "..........@@.....@@.........\n",
      ".........@@......@@.........\n",
      ".........@@.....@@@.........\n",
      ".........@@...@@@@@@........\n",
      ".........@@@@@@@@@@.........\n",
      "........@@@@@@@@@@..........\n",
      "........@@@@@.@@@@..........\n",
      "...............@@@..........\n",
      "...............@@@..........\n",
      "...............@@...........\n",
      "..............@@@...........\n",
      "..............@@............\n",
      "..............@@............\n",
      "..............@@............\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-cce8fdf6f7e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The amount of test images'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The label of random image'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'The random image is'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmndata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Images are binary with 28*28 = '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "import random\n",
    "mndata = MNIST('.\\\\data')\n",
    "\n",
    "trimages, trlabels = mndata.load_training()\n",
    "teimages, telabels = mndata.load_testing()\n",
    "index = random.randrange(0, len(trimages))  # choose an index ;-)\n",
    "print('The amount of train images',len(trimages))\n",
    "print('The amount of test images',len(teimages))\n",
    "print('The label of random image',trlabels[index],'The random image is',mndata.display(trimages[index]))\n",
    "print('Images are binary with 28*28 = ',len(teimages[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.2781 - acc: 0.9210 - val_loss: 0.1412 - val_acc: 0.9574\n",
      "Epoch 2/10\n",
      " - 9s - loss: 0.1115 - acc: 0.9676 - val_loss: 0.0921 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 10s - loss: 0.0720 - acc: 0.9795 - val_loss: 0.0791 - val_acc: 0.9768\n",
      "Epoch 4/10\n",
      " - 9s - loss: 0.0505 - acc: 0.9859 - val_loss: 0.0750 - val_acc: 0.9771\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.0374 - acc: 0.9894 - val_loss: 0.0675 - val_acc: 0.9789\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.0270 - acc: 0.9927 - val_loss: 0.0631 - val_acc: 0.9805\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.0211 - acc: 0.9947 - val_loss: 0.0616 - val_acc: 0.9810\n",
      "Epoch 8/10\n",
      " - 10s - loss: 0.0144 - acc: 0.9967 - val_loss: 0.0627 - val_acc: 0.9806\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0113 - acc: 0.9977 - val_loss: 0.0595 - val_acc: 0.9814\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.0082 - acc: 0.9985 - val_loss: 0.0587 - val_acc: 0.9821\n",
      "Baseline Error: 1.79%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cff8e627a470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmndata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_testing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# reshape to be [samples][pixels][width][height]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "# load data\n",
    "(X_train, y_train)= mndata.load_training()\n",
    "(X_test, y_test) = mndata.load_testing()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'list_devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4b826fea199a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# build the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlarger_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-4b826fea199a>\u001b[0m in \u001b[0;36mlarger_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    462\u001b[0m                 \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m                 \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                 \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3178\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown data_format '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3180\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess_conv2d_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3182\u001b[0m     \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_preprocess_conv2d_input\u001b[1;34m(x, data_format)\u001b[0m\n\u001b[0;32m   3060\u001b[0m     \u001b[0mtf_data_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3061\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3062\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_has_nchw_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3063\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# NCHW -> NHWC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_has_nchw_support\u001b[1;34m()\u001b[0m\n\u001b[0;32m    268\u001b[0m     \"\"\"\n\u001b[0;32m    269\u001b[0m     \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_is_current_explicit_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mgpus_available\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpus_available\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[1;34m()\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'GPU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Session' object has no attribute 'list_devices'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Larger CNN for the MNIST Dataset\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "# define the larger model\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "\n",
    "\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
